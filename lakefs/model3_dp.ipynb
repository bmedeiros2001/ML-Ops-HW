{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip uninstall -y numpy tensorflow tensorflow-estimator tensorflow-privacy tensorflow-probability -q\n",
        "\n",
        "!pip install tensorflow==2.15.0 -q\n",
        "!pip install tensorflow-privacy -q\n",
        "!pip install tensorflow-probability==0.23.0 -q'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRAwOf2BpCT5",
        "outputId": "cc437037-212e-4d59-9ddb-486d2102f282"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-estimator as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-privacy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tensorflow-probability>=0.13.0, which is not installed.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "xarray 2025.3.1 requires packaging>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 22.0 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-privacy 0.9.0 requires tensorflow-probability~=0.22.0, but you have tensorflow-probability 0.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
        "from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy_lib import compute_dp_sgd_privacy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "drFriSxVjefB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"athletes_v2.csv\")\n",
        "X = df.drop(columns=[\"total_lift\", \"candj\", \"snatch\", \"deadlift\",\"backsq\"])\n",
        "y = df[\"total_lift\"]"
      ],
      "metadata": {
        "id": "PaY4wmuvjXdO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize numeric columns\n",
        "numeric = X.select_dtypes(include=np.number).columns\n",
        "X[numeric] = (X[numeric] - X[numeric].mean()) / X[numeric].std()"
      ],
      "metadata": {
        "id": "hgybZ9wsp5az"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)"
      ],
      "metadata": {
        "id": "lp09Wx7cq39u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = len(X_train)\n",
        "n_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkHYaHZ2umxs",
        "outputId": "c342f667-02e1-4fcd-933c-2d7bc15e93e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24649"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "noise_multiplier = 1.1  # moderate privacy\n",
        "l2_norm_clip = 1.0      # clip gradients to this norm\n",
        "batch_size = 32         # smaller batches = better privacy\n",
        "learning_rate = 0.01    # often need lower LR with DP\n",
        "epochs = 50             # may need more due to noise\n",
        "\n",
        "# calculate delta based on dataset size\n",
        "delta = 1 / n_train\n",
        "\n",
        "# convert tensr flow to datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=n_train)\n",
        "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "from os import access\n",
        "# build model with DP optimizer\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)   # regression output\n",
        "])\n",
        "\n",
        "# create DP optimizer\n",
        "dp_optimizer = DPKerasSGDOptimizer(\n",
        "    l2_norm_clip=l2_norm_clip,\n",
        "    noise_multiplier=noise_multiplier,\n",
        "    num_microbatches=batch_size,   # process each example separately\n",
        "    learning_rate=learning_rate\n",
        ")"
      ],
      "metadata": {
        "id": "nx908cMduqH3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile with per-example loss\n",
        "model.compile(optimizer=dp_optimizer,\n",
        "              loss=tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE),\n",
        "              metrics=['mae']\n",
        "              )"
      ],
      "metadata": {
        "id": "JVuDDG_UwG6G"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_dataset,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH7y5YnrwgFV",
        "outputId": "1b786891-2723-428d-eb53-f8fb4dca1489"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "770/770 [==============================] - 4s 4ms/step - loss: 1080962.0000 - mae: 1002.5010 - val_loss: 1012960.0625 - val_mae: 968.6173\n",
            "Epoch 2/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 839027.8125 - mae: 877.0268 - val_loss: 604086.1250 - val_mae: 740.2415\n",
            "Epoch 3/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 320368.7812 - mae: 503.6274 - val_loss: 98882.0703 - val_mae: 260.5882\n",
            "Epoch 4/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 60348.8008 - mae: 194.4201 - val_loss: 50761.6055 - val_mae: 176.6268\n",
            "Epoch 5/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 45985.6016 - mae: 168.2467 - val_loss: 43940.8711 - val_mae: 164.1131\n",
            "Epoch 6/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 41235.0273 - mae: 159.5553 - val_loss: 40406.6758 - val_mae: 157.0315\n",
            "Epoch 7/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 38728.3555 - mae: 154.5964 - val_loss: 38166.4258 - val_mae: 152.4230\n",
            "Epoch 8/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 37099.0664 - mae: 151.2581 - val_loss: 36806.6953 - val_mae: 149.4175\n",
            "Epoch 9/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 36067.3906 - mae: 149.0326 - val_loss: 35798.9258 - val_mae: 147.1620\n",
            "Epoch 10/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 35211.1758 - mae: 147.1170 - val_loss: 34882.6289 - val_mae: 145.0884\n",
            "Epoch 11/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 34558.3438 - mae: 145.6191 - val_loss: 34284.0547 - val_mae: 143.5372\n",
            "Epoch 12/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 34027.5508 - mae: 144.2971 - val_loss: 33725.9141 - val_mae: 142.1411\n",
            "Epoch 13/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 33582.9883 - mae: 143.2145 - val_loss: 33307.4492 - val_mae: 140.9799\n",
            "Epoch 14/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 33270.0078 - mae: 142.3235 - val_loss: 32887.0508 - val_mae: 139.9404\n",
            "Epoch 15/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 32937.7461 - mae: 141.4978 - val_loss: 32499.3418 - val_mae: 138.9640\n",
            "Epoch 16/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 32687.3320 - mae: 140.7911 - val_loss: 32276.1895 - val_mae: 138.3119\n",
            "Epoch 17/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 32463.9844 - mae: 140.2113 - val_loss: 32074.6562 - val_mae: 137.7047\n",
            "Epoch 18/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 32301.5586 - mae: 139.7454 - val_loss: 31800.8672 - val_mae: 137.1058\n",
            "Epoch 19/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 32134.2070 - mae: 139.2594 - val_loss: 31721.3887 - val_mae: 136.6913\n",
            "Epoch 20/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 32017.1680 - mae: 138.8748 - val_loss: 31565.2500 - val_mae: 136.2670\n",
            "Epoch 21/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31935.5996 - mae: 138.5611 - val_loss: 31409.9336 - val_mae: 135.8589\n",
            "Epoch 22/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31786.2500 - mae: 138.1935 - val_loss: 31334.9434 - val_mae: 135.5489\n",
            "Epoch 23/50\n",
            "770/770 [==============================] - 4s 5ms/step - loss: 31730.9668 - mae: 137.9429 - val_loss: 31202.8730 - val_mae: 135.2143\n",
            "Epoch 24/50\n",
            "770/770 [==============================] - 4s 5ms/step - loss: 31652.1406 - mae: 137.7194 - val_loss: 31129.4199 - val_mae: 134.9706\n",
            "Epoch 25/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 31583.2070 - mae: 137.5398 - val_loss: 31156.5000 - val_mae: 134.8479\n",
            "Epoch 26/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 31561.3379 - mae: 137.3734 - val_loss: 31038.3105 - val_mae: 134.6534\n",
            "Epoch 27/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31518.4199 - mae: 137.2439 - val_loss: 30945.5312 - val_mae: 134.4894\n",
            "Epoch 28/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31455.1836 - mae: 137.1054 - val_loss: 30921.4297 - val_mae: 134.3379\n",
            "Epoch 29/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 31425.4316 - mae: 136.9765 - val_loss: 30870.5508 - val_mae: 134.2352\n",
            "Epoch 30/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31358.3926 - mae: 136.8644 - val_loss: 30836.5176 - val_mae: 134.1131\n",
            "Epoch 31/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31322.6367 - mae: 136.7329 - val_loss: 30783.5312 - val_mae: 134.0012\n",
            "Epoch 32/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 31269.3555 - mae: 136.6403 - val_loss: 30754.3008 - val_mae: 133.9454\n",
            "Epoch 33/50\n",
            "770/770 [==============================] - 4s 5ms/step - loss: 31255.1816 - mae: 136.5914 - val_loss: 30747.4570 - val_mae: 133.8932\n",
            "Epoch 34/50\n",
            "770/770 [==============================] - 4s 5ms/step - loss: 31279.7793 - mae: 136.5665 - val_loss: 30741.5723 - val_mae: 133.8662\n",
            "Epoch 35/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31260.7969 - mae: 136.5374 - val_loss: 30752.9648 - val_mae: 133.8510\n",
            "Epoch 36/50\n",
            "770/770 [==============================] - 4s 5ms/step - loss: 31260.5273 - mae: 136.4980 - val_loss: 30688.2598 - val_mae: 133.7956\n",
            "Epoch 37/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31242.0234 - mae: 136.4785 - val_loss: 30726.2695 - val_mae: 133.8052\n",
            "Epoch 38/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31220.7656 - mae: 136.4433 - val_loss: 30733.3105 - val_mae: 133.7648\n",
            "Epoch 39/50\n",
            "770/770 [==============================] - 4s 5ms/step - loss: 31190.5996 - mae: 136.3844 - val_loss: 30708.8926 - val_mae: 133.7228\n",
            "Epoch 40/50\n",
            "770/770 [==============================] - 4s 6ms/step - loss: 31218.6836 - mae: 136.4038 - val_loss: 30682.4863 - val_mae: 133.7491\n",
            "Epoch 41/50\n",
            "770/770 [==============================] - 4s 5ms/step - loss: 31194.7188 - mae: 136.3809 - val_loss: 30701.8398 - val_mae: 133.7701\n",
            "Epoch 42/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31231.2207 - mae: 136.3910 - val_loss: 30702.9902 - val_mae: 133.7317\n",
            "Epoch 43/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31211.9043 - mae: 136.3629 - val_loss: 30675.5371 - val_mae: 133.7120\n",
            "Epoch 44/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31173.5254 - mae: 136.3091 - val_loss: 30692.3730 - val_mae: 133.6875\n",
            "Epoch 45/50\n",
            "770/770 [==============================] - 3s 3ms/step - loss: 31191.9453 - mae: 136.3284 - val_loss: 30599.0312 - val_mae: 133.6256\n",
            "Epoch 46/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31164.1504 - mae: 136.2916 - val_loss: 30649.8809 - val_mae: 133.6466\n",
            "Epoch 47/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31177.7480 - mae: 136.2783 - val_loss: 30679.2383 - val_mae: 133.6306\n",
            "Epoch 48/50\n",
            "770/770 [==============================] - 3s 4ms/step - loss: 31182.8418 - mae: 136.2812 - val_loss: 30662.5039 - val_mae: 133.6292\n",
            "Epoch 49/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31184.1172 - mae: 136.2794 - val_loss: 30641.4902 - val_mae: 133.6354\n",
            "Epoch 50/50\n",
            "770/770 [==============================] - 2s 3ms/step - loss: 31144.9512 - mae: 136.2324 - val_loss: 30639.4238 - val_mae: 133.6022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
      ],
      "metadata": {
        "id": "7ssDersNx57b"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"mae: {mae:.2f}\")\n",
        "print(f\"R²: {r2:.3f}\")"
      ],
      "metadata": {
        "id": "bremzuWymi-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1c50b2-e7af-4391-df1f-9869bf5eb028"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193/193 [==============================] - 0s 788us/step\n",
            "mae: 133.60\n",
            "R²: 0.610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate epsilon (privacy spent)\n",
        "epsilon, _ = compute_dp_sgd_privacy(\n",
        "    n=n_train,\n",
        "    batch_size=batch_size,\n",
        "    noise_multiplier=noise_multiplier,\n",
        "    epochs=epochs,\n",
        "    delta=delta\n",
        ")\n",
        "print(f\"Privacy guarantee: ε = {epsilon:.2f} at δ = {delta:.2e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGXVZkAUxGwb",
        "outputId": "f3f47a53-8cf2-4abe-c5f8-d2b722bb16f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`compute_dp_sgd_privacy` is deprecated. It does not account for doubling of sensitivity with microbatching, and assumes Poisson subsampling, which is rarely used in practice. Please use `compute_dp_sgd_privacy_statement`, which provides appropriate context for the guarantee. To compute epsilon under different assumptions than those in `compute_dp_sgd_privacy_statement`, call the `dp_accounting` libraries directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy guarantee: ε = 1.10 at δ = 4.06e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- epsilon (privacy guarantee) > 1 is good!\n",
        "- δ is very small (0.0000406) which is good. This means there is only a 0.00406% chance of privacy breach.\n"
      ],
      "metadata": {
        "id": "tJWvR8jp0GHD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lEZo1AAvzsdT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}